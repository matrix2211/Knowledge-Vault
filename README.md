# ğŸ“š Knowledge Vault â€” RAG-Powered Document Q&A

A **local, ChatGPT-style Retrieval-Augmented Generation (RAG) application** that allows users to upload documents and ask questions grounded strictly in their content.

Built with **FastAPI + FAISS + Ollama**, this project focuses on **correct RAG architecture, file-scoped retrieval, and production-grade guardrails** â€” not just a toy demo.

---

## âœ¨ Features

- ğŸ“‚ Upload and manage multiple PDF documents
- ğŸ” Ask natural language questions grounded **only in selected files**
- ğŸ§  Retrieval-Augmented Generation (RAG) using vector search
- ğŸ—‚ï¸ File-scoped querying (no cross-document leakage)
- ğŸ§¾ Source attribution per answer
- ğŸš« Hallucination guards for weak or unreadable PDFs
- ğŸ’¬ ChatGPT-style UI (sidebar + chat + fixed input)
- âš™ï¸ Fully local â€” no external APIs required

---

## ğŸ—ï¸ Architecture Overview

```text
Frontend (HTML/CSS/JS)
â†“
FastAPI Backend
â†“
Embeddings (SentenceTransformers)
â†“
FAISS Vector Store
â†“
Ollama (llama3)
```


### RAG Flow
1. User uploads a PDF
2. Text is extracted, chunked, embedded
3. Embeddings stored in FAISS with metadata
4. User selects a file + asks a question
5. Retrieval happens **only within that file**
6. LLM answers strictly from retrieved context

---

## ğŸ“ Project Structure

```text

backend/
â”œâ”€â”€ embeddings.py
â”œâ”€â”€ ingest.py
â”œâ”€â”€ llm.py
â”œâ”€â”€ main.py
â”œâ”€â”€ rag.py
â”œâ”€â”€ vector_store.py
â””â”€â”€ init.py

data/
â”œâ”€â”€ documents/ # All uploaded PDFs
â””â”€â”€ faiss_index/ # Vector index + metadata

frontend/
â”œâ”€â”€ index.html
â”œâ”€â”€ style.css
â””â”€â”€ app.js

requirements.txt
README.md

```

## Website UI Preview

![ui](backend/data/documents/ui2.png)
